{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and parse XML\n",
    "(find VUAMC.xml in the git folder and download it in one directory with this parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import xml.etree.ElementTree as etree\n",
    "from lxml import etree, objectify\n",
    "\n",
    "root = etree.parse('VUAMC.xml')\n",
    "\n",
    "## Cleanup xml schema/namespaces from tags ##    \n",
    "for elem in root.getiterator():\n",
    "    if not hasattr(elem.tag, 'find'): continue  # (1)\n",
    "    i = elem.tag.find('}')\n",
    "    if i >= 0:\n",
    "        elem.tag = elem.tag[i+1:]\n",
    "objectify.deannotate(root, cleanup_namespaces=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traverse XML tree and extract sentences containing metaphors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_similes(root):\n",
    "    rows = []\n",
    "    for sent in root.findall('.//s'): # scan all sentences\n",
    "        text = ''\n",
    "        mflag = ''\n",
    "        mrw = ''\n",
    "        type_ = ''\n",
    "        for word in sent.findall('.//w'): # for each word in sentence\n",
    "            aseg = word.find('.//seg')\n",
    "            if aseg is not None:\n",
    "                if not aseg.text or not aseg.text.strip():\n",
    "                    continue\n",
    "                ft = aseg.text.strip()#.encode('UTF-8')\n",
    "                if aseg.get('function') == 'mFlag': # flag for similes\n",
    "                    mflag += ' ' + ft\n",
    "                    text += ' ' + ft\n",
    "                if aseg.get('function') == 'mrw':\n",
    "                     # and not (not mflag): # start collecting keywords only after mflag\n",
    "                    mrw += ' ' + ft\n",
    "                    text += ' ' + ft\n",
    "                    type_ = aseg.get('type')\n",
    "            elif not (not word.text):\n",
    "                text += ' ' + word.text.strip()#.encode('UTF-8')\n",
    "\n",
    "        text = text.strip()\n",
    "        mrw = mrw.strip()\n",
    "        mflag = mflag.strip()\n",
    "        if not (not mrw) and type_ == 'met': \n",
    "            rows.append([mflag, mrw, text])\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.columns = ['_', 'mrw', 'sentence']\n",
    "    return df\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This creates an xml file with metaphors and sentences w/met extracted from the corpus\n",
    "(replace with your code, when you have a classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = extract_similes(root)\n",
    "df.to_csv('metaphors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>mrw</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td></td>\n",
       "      <td>got from taking at</td>\n",
       "      <td>We 've got five weeks discouraged from taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td></td>\n",
       "      <td>take at</td>\n",
       "      <td>In Belgium many people do take three weeks at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td></td>\n",
       "      <td>with</td>\n",
       "      <td>You do come back with somebody sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8105</th>\n",
       "      <td></td>\n",
       "      <td>got got on hands</td>\n",
       "      <td>Perhaps when they come back they 've got six m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td></td>\n",
       "      <td>that</td>\n",
       "      <td>Oh well if you 're here that 's all right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _                 mrw                                           sentence\n",
       "8102    got from taking at  We 've got five weeks discouraged from taking ...\n",
       "8103               take at  In Belgium many people do take three weeks at ...\n",
       "8104                  with             You do come back with somebody sitting\n",
       "8105      got got on hands  Perhaps when they come back they 've got six m...\n",
       "8106                  that          Oh well if you 're here that 's all right"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>mrw</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>reveals approach leading to</td>\n",
       "      <td>Latest corporate unbundler reveals laid-back a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _                          mrw  \\\n",
       "0    reveals approach leading to   \n",
       "\n",
       "                                            sentence  \n",
       "0  Latest corporate unbundler reveals laid-back a...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Latest corporate unbundler reveals laid-back a...\n",
       "1       IT SEEMS that Roland Franklin the latest unbun...\n",
       "2       He has not properly investigated the target 's...\n",
       "3       The 63-year-old head of Pembridge Investments ...\n",
       "4       If he had taken his own rule seriously he woul...\n",
       "5       There are other things he has on his own admis...\n",
       "6       When the bid was launched last week Mr Frankli...\n",
       "7                     He regards the charges as unfounded\n",
       "8                                 On property he is blunt\n",
       "9            I do not regard property profits as earnings\n",
       "10      We have made a bid of nearly Â£700m for a compa...\n",
       "11      If they can prove it is there we might pay for it\n",
       "12        On the other criticism he is equally dismissive\n",
       "13      That point about the core business is very unf...\n",
       "14      We would eventually like to do it along with t...\n",
       "15      The Franklin philosophy was learnt in the US l...\n",
       "16      Mr Franklin went there at the end of the 1970s...\n",
       "17      He feels that Keyser 's problems were hastened...\n",
       "18      Along with Sir James he found the US much more...\n",
       "19      He rejects charges that he was partly responsi...\n",
       "20      We stirred it up yes but we never lost any mon...\n",
       "21      What he has learned from Goldsmith the only ge...\n",
       "22      It does not matter whether or not DRG makes se...\n",
       "23      And there is always the ultimate unbundler 's ...\n",
       "24      In a takeover campaign that has already seen v...\n",
       "25      Letter Policy and politics at the Labour Party...\n",
       "26      Sir I was interested by your juxtaposition of ...\n",
       "27      Electors are always prepared to criticise the ...\n",
       "28      Letter Policy and politics at the Labour Party...\n",
       "29      Sir Despite a significant gap in the Labour Pa...\n",
       "                              ...                        \n",
       "8077                                             With who\n",
       "8078                       Come on do n't invent you know\n",
       "8079    Going through France ah the Severn and then al...\n",
       "8080                                      It was fabulous\n",
       "8081                                      No what rubbish\n",
       "8082              But I 'm not going on holiday in a town\n",
       "8083     Well you can spend some days on the Cote d'Azure\n",
       "8084               I do n't mind for about two three days\n",
       "8085                                           strong hmm\n",
       "8086    So it looks awfully fresh the wretches made me...\n",
       "8087    Large belt large belt of the community in east...\n",
       "8088             But is n't Manto near the Italian border\n",
       "8089    Well it 's closer to the Italian border than N...\n",
       "8090    It 's quite nice we have a very nice little vi...\n",
       "8091                               Quite nice on on above\n",
       "8092                            but think what you missed\n",
       "8093    The best French cider I have drunk is a French...\n",
       "8094    The best French cider is cider sold by Sainsbu...\n",
       "8095    If you 're going in er if you 're going in tha...\n",
       "8096                  Just give me a week to have in here\n",
       "8097                                     Do you know that\n",
       "8098     But well I mean it 's rather stupid for how long\n",
       "8099          But can Vaison take the three weeks holiday\n",
       "8100                            That 's six I do n't know\n",
       "8101    We 're very reluctant to have to take three we...\n",
       "8102    We 've got five weeks discouraged from taking ...\n",
       "8103    In Belgium many people do take three weeks at ...\n",
       "8104               You do come back with somebody sitting\n",
       "8105    Perhaps when they come back they 've got six m...\n",
       "8106            Oh well if you 're here that 's all right\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With Natasha's VUAMC corpus\n",
    "# with open('metaphors.csv', 'r') as text_file:\n",
    "#     metaphor_corpus = text_file.read()\n",
    "\n",
    "metaphor_corpus = str(df[\"sentence\"])\n",
    "\n",
    "# Use default tokenizer to start with\n",
    "def tokenize_text(corpus):\n",
    "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sents = sent_tokenizer.tokenize(corpus) # Split text into sentences\n",
    "    \n",
    "    return [nltk.word_tokenize(word) for word in raw_sents]\n",
    "\n",
    "metaphor_sents = tokenize_text(metaphor_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_period.n.01 (4)\n",
      "\t week, day\n",
      "\n",
      "direction.n.06 (3)\n",
      "\t rule\n",
      "\n",
      "group.n.01 (3)\n",
      "\t people\n",
      "\n",
      "concept.n.01 (3)\n",
      "\t property, rule\n",
      "\n",
      "metallic_element.n.01 (2)\n",
      "\t u, er\n",
      "\n",
      "boundary.n.01 (2)\n",
      "\t border\n",
      "\n",
      "work_time.n.01 (2)\n",
      "\t week, day\n",
      "\n",
      "goal.n.01 (2)\n",
      "\t target, object\n",
      "\n",
      "edge.n.06 (2)\n",
      "\t border\n",
      "\n",
      "time_unit.n.01 (2)\n",
      "\t day\n",
      "\n",
      "family.n.04 (2)\n",
      "\t people, name\n",
      "\n",
      "duration.n.01 (1)\n",
      "\t rule\n",
      "\n",
      "explosive.n.01 (1)\n",
      "\t charge\n",
      "\n",
      "libidinal_energy.n.01 (1)\n",
      "\t charge\n",
      "\n",
      "possession.n.02 (1)\n",
      "\t property\n",
      "\n",
      "argumentation.n.02 (1)\n",
      "\t policy\n",
      "\n",
      "important_person.n.01 (1)\n",
      "\t name\n",
      "\n",
      "affair.n.03 (1)\n",
      "\t party\n",
      "\n",
      "causal_agent.n.01 (1)\n",
      "\t somebody\n",
      "\n",
      "literal_interpretation.n.01 (1)\n",
      "\t letter\n",
      "\n",
      "time.n.03 (1)\n",
      "\t day\n",
      "\n",
      "administrative_district.n.01 (1)\n",
      "\t town\n",
      "\n",
      "sanction.n.04 (1)\n",
      "\t name\n",
      "\n",
      "antioxidant.n.01 (1)\n",
      "\t se\n",
      "\n",
      "mon-khmer.n.01 (1)\n",
      "\t mon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def freq_normed_unigrams(sents):\n",
    "    wnl = WordNetLemmatizer() # to get word stems\n",
    "    \n",
    "    tagged_POS_sents = [nltk.pos_tag(sent) for sent in sents] # tags sents\n",
    "    \n",
    "    normed_tagged_words = [wnl.lemmatize(word[0].lower()) for sent in tagged_POS_sents\n",
    "                           for word in sent \n",
    "                           if word[0].lower() not in nltk.corpus.stopwords.words('english')\n",
    "                           and word[0] not in punctuation # remove punctuation\n",
    "                           and not re.search(r'''^[\\.,;\"'?!():\\-_`]+$''', word[0])\n",
    "                           and word[1].startswith('N')]  # include only nouns\n",
    "\n",
    "    top_normed_unigrams = [word for (word, count) in nltk.FreqDist(normed_tagged_words).most_common(40)]\n",
    "    return top_normed_unigrams\n",
    "\n",
    "def categories_from_hypernyms(sents):\n",
    "    termlist = freq_normed_unigrams(sents) # get top unigrams\n",
    "    hypterms = []\n",
    "    hypterms_dict = defaultdict(list)\n",
    "    for term in termlist:                  # for each term\n",
    "        s = wn.synsets(term.lower(), 'n')  # get its nominal synsets\n",
    "        for syn in s:                      # for each lemma synset\n",
    "            for hyp in syn.hypernyms():    # It has a list of hypernyms\n",
    "                hypterms = hypterms + [hyp.name]      # Extract the hypernym name and add to list\n",
    "                hypterms_dict[hyp.name].append(term)  # Extract examples and add them to dict\n",
    "    hypfd = nltk.FreqDist(hypterms)             # After going through all the nouns, print out the hypernyms \n",
    "    for (name, count) in hypfd.most_common(25):  # that have accumulated the most counts (have seen the most descendents)\n",
    "        print( name(), '({0})'.format(count))\n",
    "        print ('\\t', ', '.join(set(hypterms_dict[name])))  # show the children found for each hypernym\n",
    "        print ()\n",
    "        \n",
    "categories_from_hypernyms(metaphor_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_period.n.01 (4)\n",
      "\t week, day\n",
      "\n",
      "direction.n.06 (3)\n",
      "\t rule\n",
      "\n",
      "group.n.01 (3)\n",
      "\t people\n",
      "\n",
      "concept.n.01 (3)\n",
      "\t property, rule\n",
      "\n",
      "metallic_element.n.01 (2)\n",
      "\t u, er\n",
      "\n",
      "boundary.n.01 (2)\n",
      "\t border\n",
      "\n",
      "work_time.n.01 (2)\n",
      "\t week, day\n",
      "\n",
      "goal.n.01 (2)\n",
      "\t target, object\n",
      "\n",
      "edge.n.06 (2)\n",
      "\t border\n",
      "\n",
      "time_unit.n.01 (2)\n",
      "\t day\n",
      "\n",
      "family.n.04 (2)\n",
      "\t people, name\n",
      "\n",
      "duration.n.01 (1)\n",
      "\t rule\n",
      "\n",
      "explosive.n.01 (1)\n",
      "\t charge\n",
      "\n",
      "libidinal_energy.n.01 (1)\n",
      "\t charge\n",
      "\n",
      "possession.n.02 (1)\n",
      "\t property\n",
      "\n",
      "argumentation.n.02 (1)\n",
      "\t policy\n",
      "\n",
      "important_person.n.01 (1)\n",
      "\t name\n",
      "\n",
      "affair.n.03 (1)\n",
      "\t party\n",
      "\n",
      "causal_agent.n.01 (1)\n",
      "\t somebody\n",
      "\n",
      "literal_interpretation.n.01 (1)\n",
      "\t letter\n",
      "\n",
      "time.n.03 (1)\n",
      "\t day\n",
      "\n",
      "administrative_district.n.01 (1)\n",
      "\t town\n",
      "\n",
      "sanction.n.04 (1)\n",
      "\t name\n",
      "\n",
      "antioxidant.n.01 (1)\n",
      "\t se\n",
      "\n",
      "mon-khmer.n.01 (1)\n",
      "\t mon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With Metanet\n",
    "with open('metanet.txt', 'r') as text_file:\n",
    "     metaphor_corpus = text_file.read()\n",
    "\n",
    "metanet_corpus = str(df[\"sentence\"])\n",
    "\n",
    "# Use default tokenizer to start with\n",
    "def tokenize_text(corpus):\n",
    "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sents = sent_tokenizer.tokenize(corpus) # Split text into sentences\n",
    "    \n",
    "    return [nltk.word_tokenize(word) for word in raw_sents]\n",
    "\n",
    "metanet_sents = tokenize_text(metanet_corpus)\n",
    "categories_from_hypernyms(metanet_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Looking at https://github.com/ytsvetko/metaphor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##imports\n",
    "#%pylab inline\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import nltk\n",
    "import pprint\n",
    "import matplotlib\n",
    "from nltk import word_tokenize\n",
    "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "from nltk.collocations import *\n",
    "import string, random\n",
    "from nltk.corpus import brown\n",
    "from nltk.collocations import *\n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_anmet = pd.read_csv(\"an_mets.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an_metaphors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry welt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bald assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bare outline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blind alley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     an_metaphors\n",
       "0      angry welt\n",
       "1  bald assertion\n",
       "2    bare outline\n",
       "3     black humor\n",
       "4     blind alley"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anmet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>an_met</th>\n",
       "      <th>an_nonmet</th>\n",
       "      <th>svo_met</th>\n",
       "      <th>svo_nonmet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry welt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bald assertion</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bare outline</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black humor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blind alley</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sample  metaphor  an_met  an_nonmet  svo_met  svo_nonmet\n",
       "0      angry welt         1       1          0        0           0\n",
       "1  bald assertion         1       1          0        0           0\n",
       "2    bare outline         1       1          0        0           0\n",
       "3     black humor         1       1          0        0           0\n",
       "4     blind alley         1       1          0        0           0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anmet = pd.read_csv(\"an_mets.csv\", low_memory=False)\n",
    "df_anmet['metaphor'] = 1\n",
    "df_anmet['an_met'] = 1\n",
    "df_anmet['an_nonmet'] = 0\n",
    "df_anmet['svo_met'] = 0\n",
    "df_anmet['svo_nonmet'] = 0\n",
    "df_anmet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>an_met</th>\n",
       "      <th>an_nonmet</th>\n",
       "      <th>svo_met</th>\n",
       "      <th>svo_nonmet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry protester</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bald eagle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big city</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blind man</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bloody nose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sample  metaphor  an_met  an_nonmet  svo_met  svo_nonmet\n",
       "0  angry protester         0       0          1        0           0\n",
       "1       bald eagle         0       0          1        0           0\n",
       "2         big city         0       0          1        0           0\n",
       "3        blind man         0       0          1        0           0\n",
       "4      bloody nose         0       0          1        0           0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annonmet = pd.read_csv(\"an_nonmets.csv\", low_memory=False)\n",
    "df_annonmet['metaphor'] = 0\n",
    "df_annonmet['an_met'] = 0\n",
    "df_annonmet['an_nonmet'] = 1\n",
    "df_annonmet['svo_met'] = 0\n",
    "df_annonmet['svo_nonmet'] = 0\n",
    "df_annonmet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>an_met</th>\n",
       "      <th>an_nonmet</th>\n",
       "      <th>svo_met</th>\n",
       "      <th>svo_nonmet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conversation turn subject</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resumption bring relief</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economy move direction</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service meet expectation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>material live dream</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sample  metaphor  an_met  an_nonmet  svo_met  svo_nonmet\n",
       "0  conversation turn subject         1       0          0        1           0\n",
       "1    resumption bring relief         1       0          0        1           0\n",
       "2     economy move direction         1       0          0        1           0\n",
       "3   service meet expectation         1       0          0        1           0\n",
       "4        material live dream         1       0          0        1           0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svomet = pd.read_csv(\"svo_mets.csv\", low_memory=False)\n",
    "df_svomet['metaphor'] = 1\n",
    "df_svomet['an_met'] = 0\n",
    "df_svomet['an_nonmet'] = 0\n",
    "df_svomet['svo_met'] = 1\n",
    "df_svomet['svo_nonmet'] = 0\n",
    "df_svomet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>an_met</th>\n",
       "      <th>an_nonmet</th>\n",
       "      <th>svo_met</th>\n",
       "      <th>svo_nonmet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car break *none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd scream *none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*person turn *none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foot slip *none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man shake head</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sample  metaphor  an_met  an_nonmet  svo_met  svo_nonmet\n",
       "0     car break *none         0       0          0        0           1\n",
       "1  crowd scream *none         0       0          0        0           1\n",
       "2  *person turn *none         0       0          0        0           1\n",
       "3     foot slip *none         0       0          0        0           1\n",
       "4      man shake head         0       0          0        0           1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svononmet = pd.read_csv(\"svo_nonmets.csv\", low_memory=False)\n",
    "df_svononmet['metaphor'] = 0\n",
    "df_svononmet['an_met'] = 0\n",
    "df_svononmet['an_nonmet'] = 0\n",
    "df_svononmet['svo_met'] = 0\n",
    "df_svononmet['svo_nonmet'] = 1\n",
    "df_svononmet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = [df_anmet, df_annonmet, df_svomet, df_svononmet]\n",
    "df_combo = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>an_met</th>\n",
       "      <th>an_nonmet</th>\n",
       "      <th>svo_met</th>\n",
       "      <th>svo_nonmet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>mad sprint</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>hollow cylinder</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>bolt refuse *none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>*person stare stone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>deep understanding</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>deep sea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>insurance cover care</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>statue stand *none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>sunny disposition</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>steep hill</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sample  metaphor  an_met  an_nonmet  svo_met  svo_nonmet\n",
       "500            mad sprint         1       1          0        0           0\n",
       "501       hollow cylinder         0       0          1        0           0\n",
       "502     bolt refuse *none         1       0          0        1           0\n",
       "503   *person stare stone         0       0          0        0           1\n",
       "504    deep understanding         1       1          0        0           0\n",
       "505              deep sea         0       0          1        0           0\n",
       "506  insurance cover care         1       0          0        1           0\n",
       "507    statue stand *none         0       0          0        0           1\n",
       "508     sunny disposition         1       1          0        0           0\n",
       "509            steep hill         0       0          1        0           0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_index = np.random.permutation(df_combo.index)\n",
    "random_index[:10]\n",
    "df_combo.ix[random_index, ['sample', 'metaphor', 'an_met', 'an_nonmet', 'svo_met', 'svo_nonmet']]\n",
    "df_shuffled = df_combo.ix[random_index, ['sample', 'metaphor', 'an_met', 'an_nonmet', 'svo_met', 'svo_nonmet']]\n",
    "df_shuffled.reset_index(drop=True, inplace=True)\n",
    "df_shuffled[500:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1644\n",
      "Columns: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 6)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, columns = df_shuffled.shape\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Columns:\", columns)\n",
    "#train_size = round(rows*.6)\n",
    "train_size = round(rows*.9)\n",
    "#dev_size   = round(rows*.2)\n",
    "dev_size   = round(rows*.1)\n",
    "df_train = df_shuffled.loc[:train_size]\n",
    "df_train.shape\n",
    "df_dev = df_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)\n",
    "df_dev.shape\n",
    "df_test = df_shuffled.loc[dev_size+train_size:].reset_index(drop=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', analyzer=u'word', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr_train_feature_sparse = vec.fit_transform(df_train['sample'])\n",
    "arr_train_feature_sparse\n",
    "arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "feature_labels = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_dev_feature_sparse = vec.transform(df_dev[\"sample\"])\n",
    "arr_dev_feature = arr_dev_feature_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60365853658536583"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_model = logreg.fit(arr_train_feature, df_train['metaphor']) #defining features (from reviews) and passing in Category label\n",
    "logreg_predictions = logreg_model.predict(arr_dev_feature)\n",
    "accuracy_score(df_dev['metaphor'], logreg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
